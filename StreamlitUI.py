import streamlit as st
import numpy as np
from Resource import LOGO_BASE64

class VisionUI:
    """
    M·ªôt l·ªõp ƒë·ªÉ ƒë√≥ng g√≥i v√† qu·∫£n l√Ω to√†n b·ªô giao di·ªán ng∆∞·ªùi d√πng (UI)
    c·ªßa ·ª©ng d·ª•ng Vision AI Assistant tr√™n Streamlit.
    """
    def __init__(self, camera_api):
        """Kh·ªüi t·∫°o c√°c gi√° tr·ªã v√† c·∫•u h√¨nh ban ƒë·∫ßu."""
        st.set_page_config(
            page_title="Vision AI Assistant",
            layout="wide"
        )
        # L∆∞u camera_api ƒë·ªÉ s·ª≠ d·ª•ng trong c√°c h√†m kh√°c
        self.api = camera_api

        self._initialize_session_state()
        self.cameras_info = self._get_camera_list()
        self.image_placeholder = None

    def _initialize_session_state(self):
        """Kh·ªüi t·∫°o c√°c bi·∫øn c·∫ßn thi·∫øt trong st.session_state."""
        if "messages" not in st.session_state:
            st.session_state.messages = [{"role": "assistant", "content": "How can I help you today?"}]
        if "selected_serial" not in st.session_state:
            st.session_state.selected_serial = None

        # Kh·ªüi t·∫°o tr·∫°ng th√°i cho c√°c toggle, m·∫∑c ƒë·ªãnh l√† T·∫ÆT (False)
        if "connect_status" not in st.session_state:
            st.session_state.connect_status = False
        if "stream_status" not in st.session_state:
            st.session_state.stream_status = False
            
    def _get_camera_list(self):
        try:
            available_cameras = self.api.list_cameras()
            if not available_cameras:
                st.warning("No cameras found. Please connect a camera.")
                return {"No Camera Found": {"serial": None, "model": "N/A", "info": "N/A"}}
            # Chuy·ªÉn ƒë·ªïi list[CameraInfo] th√†nh dict mong mu·ªën
            cam_dict = {}
            for cam in available_cameras:
                label = f"{cam.friendly_name}"
                cam_dict[label] = {
                    "serial": cam.serial_number,
                    "model": cam.friendly_name,
                    "info": cam.info
                }
            return cam_dict
        except Exception as e:
            st.error(f"Error fetching camera list: {e}")
            return {"Error": {"serial": None, "model": str(e), "info": "N/A"}}
    
    # C√°c h√†m callback ƒë·ªÉ x·ª≠ l√Ω khi toggle thay ƒë·ªïi
    def _handle_connect_toggle(self):
        """H√†m ƒë∆∞·ª£c g·ªçi khi toggle 'Connect/Disconnect' thay ƒë·ªïi."""
        # st.session_state.connect_status ƒë√£ ƒë∆∞·ª£c t·ª± ƒë·ªông c·∫≠p nh·∫≠t
        # tr∆∞·ªõc khi h√†m n√†y ƒë∆∞·ª£c g·ªçi.
        serial = st.session_state.selected_serial
        st.toast(f"üîå Connecting/Disconnecting camera...{serial}")
        if st.session_state.connect_status:
            if not serial:
                st.toast("‚ö†Ô∏è Please select a camera first!", icon="‚ö†Ô∏è")
                st.session_state.connect_status = False
                return
            st.toast(f"üöÄ Connecting to camera {serial}...")
            is_ok = self.api.connect(serial=serial)
            if is_ok:
                st.toast("‚úÖ Connection successful!", icon="‚úÖ")
                st.session_state.connect_status = True
                  # B·∫Øt ƒë·∫ßu stream ngay khi k·∫øt n·ªëi th√†nh c√¥ng
            else:
                st.toast("‚ùå Connection failed!", icon="‚ùå")
                st.session_state.stream_status = False
        else:
            st.toast("üîå Disconnecting camera...")
            # << TH√äM LOGIC NG·∫ÆT K·∫æT N·ªêI PYPYLON C·ª¶A B·∫†N V√ÄO ƒê√ÇY >>
            self.api.disconnect()
            st.toast("‚úÖ Disconnected successfully!", icon="‚úÖ")
            # Khi ng·∫Øt k·∫øt n·ªëi, c≈©ng n√™n t·∫Øt stream
            st.session_state.stream_status = False
            st.session_state.connect_status = False

    def _handle_stream_toggle(self):
        """H√†m ƒë∆∞·ª£c g·ªçi khi toggle 'Start/Stop Stream' thay ƒë·ªïi."""
        if st.session_state.stream_status:
            try:
                self.api.start_stream()
            except Exception as e:
                st.toast(f"‚ùå Failed to start stream: {e}", icon="‚ùå")
                st.session_state.stream_status = False
                return
            # Ch·ªâ cho ph√©p stream khi ƒë√£ k·∫øt n·ªëi
            if not self.api.is_connected:
                st.toast("‚ö†Ô∏è Please connect to a camera first!", icon="‚ö†Ô∏è")
                st.session_state.stream_status = False # T·ª± ƒë·ªông g·∫°t l·∫°i v·ªÅ Off
                return
            
            st.toast("üé• Starting stream...")
            # << TH√äM LOGIC B·∫ÆT ƒê·∫¶U STREAM C·ª¶A B·∫†N V√ÄO ƒê√ÇY >>
            self.api.start_stream()
            st.session_state.stream_status = True
        else:
            if self.api.is_connected:
                
                st.toast("üõë Stopping stream.")
                self.api.stop_stream()
                # << TH√äM LOGIC D·ª™NG STREAM C·ª¶A B·∫†N V√ÄO ƒê√ÇY >>
                st.session_state.stream_status = False
    
    def handle_capture_button(self):
        """X·ª≠ l√Ω s·ª± ki·ªán khi ng∆∞·ªùi d√πng nh·∫•n n√∫t 'Capture'."""
        if not self.api.is_connected:
            st.toast("‚ö†Ô∏è Please connect to a camera first!", icon="‚ö†Ô∏è")
            return
        
        st.toast("üì∏ Capturing image...")
        img = self.api.get_image()
        if img is not None:
            st.session_state.captured_image = img
            with st.dialog("Captured Image"):
                st.image(img, caption=f"Captured from {st.session_state.selected_serial}", use_column_width=True)
            st.session_state.messages.append({"role": "assistant", "content": "Image captured successfully!"})
        else:
            st.toast("‚ùå Failed to capture image!", icon="‚ùå")

    def _inject_custom_css(self):
        """Nh√∫ng m√£ CSS t√πy ch·ªânh v√†o ·ª©ng d·ª•ng."""
        st.markdown("""
        <style>
            /* --- Background ch√≠nh v√† m√†u ch·ªØ m·∫∑c ƒë·ªãnh --- */
            [data-testid="stAppViewContainer"] > .main {
                background-color: #57564F;
            }
            body, [data-testid="stMarkdown"], [data-testid="stHeader"] {
                color: #F8F3CE;
            }

            /* --- Style chung cho c√°c widget --- */
            [data-testid="stSelectbox"], [data-testid="stChatMessage"] {
                background-color: #7A7A73;
                border-radius: 10px;
            }
            
            /* --- Style cho c√°c container c·ª• th·ªÉ b·∫±ng class --- */
            /* Container cho l·ªãch s·ª≠ chat */
            .chat-container {
                background-color: #7A7A73; /* M√†u m·∫∑c ƒë·ªãnh */
                border-radius: 10px;
                padding: 10px;
            }
            /* Container cho parser setting, c√≥ m√†u n·ªÅn kh√°c */
            .parser-container {
                background-color: #4a4a44; /* M√†u t·ªëi h∆°n ƒë·ªÉ ph√¢n bi·ªát */
                border-radius: 10px;
                padding: 15px;
            }
            
            /* --- C√°c style kh√°c --- */
            [data-testid="stSelectbox"] div, [data-testid="stChatMessage"] p, [data-testid="stTextInput"] div {
                color: #000000 !important;
            }
            [data-testid="stButton"] button {
                background-color: #7A7A73; color: #F8F3CE; border: 1px solid #F8F3CE;
                border-radius: 5px; width: 100%;
            }
            [data-testid="stButton"] button:hover {
                background-color: #57564F; color: #F8F3CE; border: 1px solid #FFFFFF;
            }
            [data-testid="stImage"] img {
                background-color: white; padding: 5px; border-radius: 10px;
            }
            .block-container { padding: 2rem; }
        </style>
        """, unsafe_allow_html=True)

    def _render_left_panel(self):
        """V·∫Ω c·ªôt b√™n tr√°i ch·ª©a c√°c th√†nh ph·∫ßn ƒëi·ªÅu khi·ªÉn camera."""
        with st.container():
            st.header("Camera Control")

            top_cols = st.columns([1, 3, 2, 1], gap="medium")
            with top_cols[0]:
                st.image(f"data:image/png;base64,{LOGO_BASE64}", width=120)

            with top_cols[1]:
                is_disabled = not st.session_state.connect_status
                camera_options = list(self.cameras_info.keys())
                selected_camera_name = st.selectbox("List Camera", options=camera_options, label_visibility="collapsed")
                
                if selected_camera_name:
                    st.session_state.selected_serial = self.cameras_info[selected_camera_name]["serial"]
                    with st.expander(f"Details for {selected_camera_name}"):
                        st.json(self.cameras_info[selected_camera_name])
            with top_cols[2]:
                
                connect_label = "Disconnect" if st.session_state.connect_status else "Connect"
                st.toggle(
                    label=connect_label,
                    key="connect_status",
                    on_change=self._handle_connect_toggle,
                )

                stream_label = "Stop" if st.session_state.stream_status else "Start"
                st.toggle(
                    label=stream_label,
                    key="stream_status",
                    on_change=self._handle_stream_toggle,
                )
                
            top_cols[3].button("Capture", key="capture_image", on_click=self.handle_capture_button, use_container_width=True)
            top_cols[3].button("Analyze", key="analyze", use_container_width=True)
            
            st.markdown("---")
            st.subheader("Show Image Stream")
            self.image_placeholder = st.empty()
            placeholder_frame = np.full((720, 1280, 3), 122, dtype=np.uint8)
            self.image_placeholder.image(placeholder_frame, caption="Camera feed will appear here.", use_column_width=True)

    def _render_right_panel(self):
        """V·∫Ω c·ªôt b√™n ph·∫£i ch·ª©a c√°c th√†nh ph·∫ßn chat."""
        with st.container():
            st.header("AI Assistant")

            # --- L·ªãch s·ª≠ Chat v·ªõi class CSS t√πy ch·ªânh ---
            st.subheader("History Chat")
            # B·ªçc container trong m·ªôt div v·ªõi class t√πy ch·ªânh
            st.markdown('<div class="chat-container">', unsafe_allow_html=True)
            with st.container(height=400, border=False):
                for message in st.session_state.messages:
                    with st.chat_message(message["role"]):
                        st.markdown(message["content"])
            st.markdown('</div>', unsafe_allow_html=True)
            
            st.markdown("---")

            # --- Parser Setting v·ªõi class CSS t√πy ch·ªânh ---
            st.subheader("Parser Setting")
            # B·ªçc text_area trong m·ªôt div v·ªõi class t√πy ch·ªânh kh√°c
            st.markdown('<div class="parser-container">', unsafe_allow_html=True)
            st.text_area(
                "Agent's processed result",
                value="{\n  \"object_detected\": \"gear\",\n  \"status\": \"OK\",\n  \"confidence\": 0.98\n}",
                height=150,
                disabled=True,
                label_visibility="collapsed"
            )
            st.markdown('</div>', unsafe_allow_html=True)

            # --- Input prompt ---
            if prompt := st.chat_input("Prompt request..."):
                st.session_state.messages.append({"role": "user", "content": prompt})
                # ... logic x·ª≠ l√≠ v√† ph·∫£n h·ªìi c·ªßa bot ...
                response = f"Echo from bot: {prompt}"
                st.session_state.messages.append({"role": "assistant", "content": response})
                st.rerun() # Ch·∫°y l·∫°i script ƒë·ªÉ c·∫≠p nh·∫≠t giao di·ªán chat

    def render(self):
        """Ph∆∞∆°ng th·ª©c ch√≠nh ƒë·ªÉ v·∫Ω to√†n b·ªô giao di·ªán."""
        self._inject_custom_css()
        
        col_cam, col_chat = st.columns([3, 2], gap="large")

        with col_cam:
            self._render_left_panel()

        with col_chat:
            self._render_right_panel()


# --- ƒêi·ªÉm b·∫Øt ƒë·∫ßu ch·∫°y ·ª©ng d·ª•ng ---
if __name__ == "__main__":
    app = VisionUI(None)
    app.render()

#streamlit run StreamlitUI.py --logger.level=debug